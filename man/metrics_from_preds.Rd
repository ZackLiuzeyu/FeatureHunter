% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utils.R
\name{metrics_from_preds}
\alias{metrics_from_preds}
\title{/ Compute classification metrics from predictions}
\usage{
metrics_from_preds(pred, true)
}
\arguments{
\item{pred}{0/1/
A vector of predicted labels, ideally 0/1 (logical or integer; coerced to integer).}

\item{true}{0/1
A vector of ground-truth labels (0/1; coerced to numeric).}
}
\value{
A named numeric vector with:
\code{F1}: F1
\code{ACC}: (accuracy)
\code{RECALL}: (recall)
}
\description{
(ACC) (RECALL)
F1
Computes standard binary classification metrics: accuracy (ACC), recall, and F1 score
from predicted and true labels.
}
\details{
ACC = /
RECALL = TP / (TP + FN) 0 0
F1 = 2TP / (2TP + FP + FN) 0 0
Metrics are computed as:
ACC = mean of correct predictions
Recall = TP / (TP+FN), returns 0 if denominator = 0
F1 = 2TP / (2TP+FP+FN), returns 0 if denominator = 0
}
\examples{
pred <- c(1,0,1,0,1)
true <- c(1,0,0,0,1)
metrics_from_preds(pred, true)
# F1, ACC, RECALL
}
