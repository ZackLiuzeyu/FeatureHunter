% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utils.R
\name{build_mlp}
\alias{build_mlp}
\title{(MLP) / Build a multilayer perceptron (MLP) model}
\usage{
build_mlp(input_dim, dropout_rate, lr, use_bias_init = FALSE, bias_value = 0)
}
\arguments{
\item{input_dim}{Input dimension (integer or vector) specifying the input shape of the model.}

\item{dropout_rate}{dropout (0 to 1)
Dropout rate (0 to 1), applied to hidden layers to reduce overfitting.}

\item{lr}{Adam
Learning rate for the Adam optimizer.}

\item{use_bias_init}{\code{FALSE}
Logical; whether to use a custom bias initializer for the output layer (default \code{FALSE}).}

\item{bias_value}{\code{use_bias_init=TRUE}
Numeric value for output layer bias initialization when \code{use_bias_init=TRUE}.}
}
\value{
Keras \code{fit()}
A compiled Keras model object, ready for training via \code{fit()}.
}
\description{
Keras MLP
dropout sigmoid Adam
ROC AUC PRC AUC
Builds a multilayer perceptron (MLP) for binary classification using Keras,
with dense layers, dropout regularization, sigmoid output, Adam optimizer,
binary cross-entropy loss, and evaluation metrics (ROC AUC and PRC AUC).
}
\details{
Dense(32, ReLU), then Dropout
Dense(16, ReLU), then Dropout
Dense(8, ReLU), then Dropout
Dense(1, Sigmoid)
Adam (\code{learning_rate = lr})

AUC (ROC) AUC (PRC)
This architecture is a simple MLP suitable for binary classification tasks,
with optional bias initialization to adjust initial output probabilities.
}
\examples{
\dontrun{
model <- build_mlp(input_dim = 100, dropout_rate = 0.5, lr = 1e-3)
summary(model)
}
}
