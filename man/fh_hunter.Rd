% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fh_hunter.R
\name{fh_hunter}
\alias{fh_hunter}
\title{Universal Feature Hunter across Multiple ML Models}
\usage{
fh_hunter(
  train_exp,
  train_labels,
  nshow,
  namesS = c("Accuracy", "Recall", "F-score"),
  score_index = 3,
  pick_index = 1,
  top_models_csv = NULL,
  num_runs = 10,
  num_coregene,
  n_likes,
  n_interest,
  seed = 424,
  out_dir = getwd(),
  learningratei = NULL,
  batch_sizei = NULL,
  epochselecti = NULL,
  dropoutratei = NULL,
  cutoffi = NULL,
  perm_metric = "f1",
  perm_nrep = 3L,
  shap_nsim = 10L,
  shap_subsample = 100L,
  svm_cost = 1,
  svm_gamma = NULL,
  xgb_nrounds = 200,
  xgb_eta = 0.05,
  xgb_max_depth = 4,
  rf_num_trees = 500,
  rf_mtry = NULL,
  shuffle = TRUE,
  standardize = NULL,
  hidden_units = NULL,
  activation = NULL,
  use_batchnorm = NULL,
  l2 = NULL,
  gaussian_noise_sd = NULL,
  min_lr = NULL,
  plateau_factor = NULL,
  plateau_patience = NULL,
  early_patience = NULL,
  imbalance_thresh = NULL,
  auto_th_method = NULL,
  method_weights = c(model = 1, perm = 1, shap = 1),
  ci_level = 0.95,
  strict_min_freq = NULL,
  strict_min_effect = NULL,
  strict_ci_gate = FALSE,
  strict_knee = FALSE,
  strict_nmax = NULL,
  apply_selection_to_plots = FALSE
)
}
\arguments{
\item{train_exp}{Numeric matrix of predictors (samples x features).}

\item{train_labels}{Response vector (0/1, factor, or convertible).}

\item{nshow}{Number of models shown in leaderboard.}

\item{namesS}{Character vector of metric names shown in leaderboard
(default: \code{c("Accuracy","Recall","F-score")}).}

\item{score_index}{Integer index of metric to rank by (default: 3 = F-score).}

\item{pick_index}{Row index of leaderboard to pick (default: 1). Works for any model type.}

\item{top_models_csv}{Path to leaderboard CSV (auto-inferred if \code{NULL}).}

\item{num_runs}{Number of repeat runs (seeds) (default: 10).}

\item{num_coregene}{Number of core genes to keep in stability/importance plots.}

\item{n_likes}{Number of top genes to use in downstream analysis (UMAP, logistic).}

\item{n_interest}{Number of genes to show in the stability heatmap.}

\item{seed}{Random seed (default: 424).}

\item{out_dir}{Output directory for plots (default: working dir).}

\item{learningratei, batch_sizei, epochselecti, dropoutratei, cutoffi}{Optional overrides for MLP hyperparameters (if \code{NULL}, use internal defaults
or values parsed from the leaderboard string where applicable).}

\item{perm_metric}{Performance metric for permutation importance (\code{"f1"} or \code{"prauc"}).}

\item{perm_nrep}{Number of repetitions for permutation (default: 3).}

\item{shap_nsim}{Number of Monte Carlo simulations for SHAP (default: 10).}

\item{shap_subsample}{Number of samples for SHAP subsampling (default: 100).}

\item{svm_cost}{Cost parameter for SVM (default: 1).}

\item{svm_gamma}{Gamma for SVM-RBF (default: \code{1/p} if \code{NULL}).}

\item{xgb_nrounds, xgb_eta, xgb_max_depth}{Hyperparameters for XGBoost
(defaults: \code{200}, \code{0.05}, \code{4}).}

\item{rf_num_trees, rf_mtry}{Hyperparameters for Random Forest
(defaults: \code{500} trees, \code{sqrt(p)} mtry if \code{NULL}).}

\item{shuffle}{Logical; whether to shuffle data each epoch in MLP training (default: \code{TRUE}).}

\item{standardize}{logical; if TRUE, standardize using train-set mean/sd and apply to val/test.
Default: NULL (auto).}

\item{hidden_units}{integer vector; number of units per hidden layer,
e.g. c(32L,16L,8L) or c(64L,32L,16L,8L). Default: NULL (auto).}

\item{activation}{character; activation function for hidden layers,
e.g. "relu". Default: NULL (auto).}

\item{use_batchnorm}{logical; whether to insert BatchNorm after each hidden Dense.
Default: NULL (auto).}

\item{l2}{numeric; L2 regularization strength (e.g. 1e-4). Default: NULL (auto).}

\item{gaussian_noise_sd}{numeric; stddev for input GaussianNoise layer.
Default: NULL (disabled).}

\item{min_lr}{numeric; minimum learning rate for ReduceLROnPlateau.
Default: NULL (auto).}

\item{plateau_factor}{numeric; factor for ReduceLROnPlateau (e.g. 0.5).
Default: NULL (auto).}

\item{plateau_patience}{integer; patience (epochs) for ReduceLROnPlateau.
Default: NULL (auto).}

\item{early_patience}{integer; patience (epochs) for EarlyStopping.
Default: NULL (auto).}

\item{imbalance_thresh}{numeric in \eqn{[0,1]}; threshold for enabling imbalance handling.
Default: NULL (auto).}

\item{auto_th_method}{character; "youden", "f1", or "auto" for thresholding.
Default: NULL (auto).}

\item{method_weights}{length-3 named numeric vector for composite weighting,
names must be c("model","perm","shap"). Default: c(model=1, perm=1, shap=1).}

\item{ci_level}{numeric; CI level for composite bootstrap over runs (default 0.95).}

\item{strict_min_freq}{numeric; minimum cross-run hit frequency in per-run Top-K to keep a gene
(e.g. 0.6 to 0.7). NULL disables.}

\item{strict_min_effect}{numeric; minimum composite mean to keep a gene on the composite scale.
NULL disables.}

\item{strict_ci_gate}{logical; if TRUE, require composite CI lower bound > 0.
Default: FALSE.}

\item{strict_knee}{logical; if TRUE, apply a knee cutoff on sorted composite means.
Default: FALSE.}

\item{strict_nmax}{integer; optional hard cap after knee (e.g. 10). NULL disables.}

\item{apply_selection_to_plots}{logical; if TRUE, bar/UMAP use selected genes;
default FALSE keeps original plotting behavior.}
}
\value{
A list with elements:
\item{params}{List of parsed parameters and metadata}
\item{importance_df}{Data frame with per-gene importance scores (3 methods + composite)}
\item{top_list}{List of top genes per run}
\item{final_top}{Vector of selected top genes after selection controls}
\item{composite_mat}{Matrix of per-run composite scores}
\item{glm_summary}{Summary of logistic regression on top genes (coefficients + formula)}
}
\description{
Automatically detect the selected model type (MLP / RF / GLMNET / XGBoost / SVM / LDA / QDA / Naive Bayes)
from a leaderboard, train the corresponding model, and compute three types of feature importance:
\itemize{
\item Model-based importance (weights, coefficients, gain, etc.)
\item Permutation importance (performance drop by shuffling a feature)
\item SHAP importance (model-agnostic explanation)
}
The three importance scores are fused via robust z-scores (median/MAD) into a composite score to rank features.
To reduce variance, multiple seeds are trained, predictions are ensembled first, then permutation/SHAP are computed
on the ensemble predictor; error bars use bootstrap CI over per-run composite scores.
}
\details{
Output files in \code{out_dir}:
\itemize{
\item FI_Boxplot_Top20.pdf: Top-20 feature importance distributions
\item FI_Bar_TopComposite.pdf: Top-N composite feature importance bar plot (mean with 95\% CI)
\item FI_Density_AllMethods.pdf: Distribution comparison of all importance methods
\item UMAP_TopSignatureGenes.pdf: UMAP projection of top genes
\item Stability_TopGenes_Heatmap.pdf: Stability heatmap of top genes across runs
}
}
\examples{
\dontrun{
res <- fh_hunter(
  train_exp = X, train_labels = Y,
  nshow = 40, score_index = 3, pick_index = 1,
  num_runs = 5, num_coregene = 50, n_likes = 30, n_interest = 30,
  strict_min_freq = 0.65, strict_ci_gate = TRUE, strict_knee = TRUE, strict_nmax = 10
)
head(res$importance_df)
}
}
